# HandGestureRecognition

## **Hand Gesture Recognition App with Android Studio**

![About Us](images/menu.PNG?raw=true "Menu Screen")



**The idea of the project:**

* Modern smartphones are becoming more and more powerful and with that come many new possibilities of how they can improve your life, by applications that could only run on more powerful devices like PCs. We decided to use that by creating a mobile image processing app that uses neural networks to classify real-time images.


* Next came the target group. We have decided to bring forth a social group that can uniquely benefit from this kind of technology, the Deaf Community. For years they have used hand shapes, positions, and movements to communicate and express ideas. But unfortunately, not everybody can "hear" them. Applications like ours bring us closer to the rest of society. Our aim became to reduce the difficulties experienced by people with disabilities while communicating. Using defined hand gestures, our app can detect them, translate them into texts and then vocalize these texts. In the end, our goal is to provide these people with a more comfortable form of communication with non-sign language speaking people, by using gestures that are natural to them.


**Training**

* We used Tensorflow Lite to train the hand gestures.

![About Us](images/training.PNG?raw=true "Training Screen")


* And this is the app screen when we try to detect the hand gestures.

![About Us](images/training.PNG?raw=true "Training Screen")


***If you want to read the report of the project, click on the link below.**

* https://github.com/cihanyatbaz/HandGestureRecognition/blob/master/Hand_Gesture_App.pdf
